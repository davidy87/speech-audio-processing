{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training network\n",
      "Training finished.\n",
      "\n",
      "Test accuracy: 58 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load('lab2_dataset.npz')\n",
    "train_feats = torch.tensor(data['train_feats'])\n",
    "test_feats = torch.tensor(data['test_feats'])\n",
    "train_labels = torch.tensor(data['train_labels'])\n",
    "test_labels = torch.tensor(data['test_labels'])\n",
    "phone_labels = data['phone_labels']\n",
    "\n",
    "# Set up the dataloaders\n",
    "train_dataset = torch.utils.data.TensorDataset(train_feats, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_feats, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # TODO: Fill in the model's layers here\n",
    "        self.fnn = nn.Sequential(nn.Linear(11 * 40, 4096), nn.Sigmoid(), nn.Linear(4096, 48))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Fill in the forward pass here\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fnn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = MyModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    \n",
    "def train_network(model, train_loader, criterion, optimizer):\n",
    "    # TODO: fill in\n",
    "    print(\"Begin training network\")\n",
    "    for epoch in range(10):\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    print(\"Training finished.\\n\")\n",
    "\n",
    "label_list = []\n",
    "correct_count = defaultdict(int)\n",
    "incorrect_count = defaultdict(int)\n",
    "\n",
    "def test_network(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # For computing accuracy for each class\n",
    "            label_list.append(labels)\n",
    "            for i, label in enumerate(labels):\n",
    "                if predicted[i] == label:\n",
    "                    correct_count[phone_labels[label]] += 1\n",
    "                elif phone_labels[label] == \"sh\" and label in predicted:\n",
    "                    incorrect_count[phone_labels[predicted[i]]] += 1\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "                \n",
    "    print('Test accuracy: %d %%' % (100 * correct / total))\n",
    "    \n",
    "train_network(model, train_loader, criterion, optimizer)\n",
    "test_network(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sh', 90.0), ('sil', 89.0), ('s', 88.0)]\n",
      "[('uh', 27.0), ('ih', 26.0), ('zh', 20.54794520547945)]\n",
      "\n",
      "Accruacy for sh: 90.0\n",
      "Accruacy for p: 41.0\n",
      "Accruacy for m: 66.0\n",
      "Accruacy for r: 59.0\n",
      "Accruacy for ae: 57.0\n"
     ]
    }
   ],
   "source": [
    "labels_counter = Counter(torch.cat(label_list).tolist())\n",
    "total_acc = 0.0\n",
    "individual_acc = {}\n",
    "\n",
    "for k, v in labels_counter.items():\n",
    "    individual_acc[phone_labels[k]] = 100 * correct_count[phone_labels[k]] / v\n",
    "\n",
    "three_highest = Counter(individual_acc).most_common(3)\n",
    "three_lowest = Counter(individual_acc).most_common()[-3:]\n",
    "\n",
    "print(three_highest)\n",
    "print(three_lowest)\n",
    "print()\n",
    "\n",
    "phonemes_to_check = ['sh', 'p', 'm', 'r', 'ae']\n",
    "for phoneme in phonemes_to_check:\n",
    "    print(\"Accruacy for {}: {}\".format(phoneme, individual_acc[phoneme]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'s': 15, 'f': 2, 'ch': 9, 'zh': 1})\n"
     ]
    }
   ],
   "source": [
    "print(incorrect_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
